{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMP68RKT5GVEDUy2BiVp6GD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Harithelamin/Is-poisonous/blob/main/Is_poisonous.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "This is a python application to identify whether the mushroom is poisonous or not using Deep Learning,  Neural Networks (CNNs), unsupervised learning.\n",
        "\n",
        "The dataset, was collected from some public ressources.\n",
        "\n",
        "The data is unlabeled images arranged in two classes, Poisonous, and Edible.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "6dP-Y1SiWIlG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "d_q1kMhC7t7n"
      },
      "outputs": [],
      "source": [
        "def application_started():\n",
        "    #\n",
        "    print(' Is-poisonous Application Started, This is to identify whether the mushroom is poisonous or not using Deep Learning')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Importing, Python, and ML libraries\n"
      ],
      "metadata": {
        "id": "g4l5zNKeGwzn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np, pandas as pd, matplotlib.pyplot as plt, random, io,  tensorflow as tf, tensorflow as keras\n",
        "from keras import Sequential\n",
        "import glob\n",
        "from shutil import copy\n",
        "from keras.src.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "isQq1xpTGk05"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "print installed libraries"
      ],
      "metadata": {
        "id": "3VjXOn7OYtgR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def print_installed_libraries():\n",
        "    import pkg_resources\n",
        "\n",
        "    installed_packages = pkg_resources.working_set\n",
        "    for package in installed_packages:\n",
        "        print(f\"{package.key}=={package.version}\")"
      ],
      "metadata": {
        "id": "xl2fF-1MHKlO"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "vKTCraAfFvUo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "68983c88-7689-45bb-eccb-3059561f5136"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define a Python class, to show datasets information"
      ],
      "metadata": {
        "id": "ylJP93k_Y_iP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# First we have to define dataset class we are going to use download datasets from url\n",
        "class Dataset:\n",
        "    # class variables\n",
        "    packageName = \"Norwegian Mushroom\"\n",
        "\n",
        "    # constructor\n",
        "    def __init__(self, code, link, cite, data):\n",
        "        self.code = code\n",
        "        self.id = id\n",
        "        self.link = link\n",
        "        self.data = data\n",
        "        self.cite = cite\n",
        "\n",
        "        # Instance method\n",
        "\n",
        "    def show(self):\n",
        "        print('Inside instance method')\n",
        "        # access using class name\n",
        "        print(Dataset.packageName)\n",
        "        # access using self\n",
        "        print(self.code, self.link, self.cite)"
      ],
      "metadata": {
        "id": "JwLU7UTJFR8F"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Datasets resources"
      ],
      "metadata": {
        "id": "aCGkMWlrZSrI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining dataset resources\n",
        "#https://archive.ics.uci.edu/dataset/73/mushroom\n",
        "\n",
        "# Loading Data from urls\n",
        "def loadingData():\n",
        "    print('Loading Data')\n",
        "    # Download\n",
        "    print(\"Download database 1\")\n",
        "\n",
        "    # Define the first online dataset with details.\n",
        "    dataset1 =  Dataset(1,\n",
        "                       \"https://archive.ics.uci.edu/dataset/73/mushroom\",\n",
        "                       \"Mushroom. (1987). UCI Machine Learning Repository. https://doi.org/10.24432/C5959T.\",\n",
        "                       (\"https://archive.ics.uci.edu/dataset/73/mushroom\",)\n",
        "                       )\n",
        "    dataset1.show()\n",
        "    # Define the second online dataset with details.\n",
        "    dataset2 = Dataset(2,\n",
        "                       \"https://www.kaggle.com/datasets/maysee/mushrooms-classification-common-genuss-images\",\n",
        "                       \"from https://www.kaggle.com/datasets/maysee/mushrooms-classification-common-genuss-images.\",\n",
        "                       (\"https://www.kaggle.com/maysee/mushrooms-classification-common-genuss-images\",)\n",
        "                       )\n",
        "    dataset2.show()\n",
        "\n",
        "    # Define the third online dataset with details.\n",
        "    dataset3 = Dataset(3,\n",
        "                       \"https://datahub.io/machine-learning/mushroom#resource-mushroom\",\n",
        "                       \"https://datahub.io/machine-learning/mushroom#resource-mushroom\",\n",
        "                       (\"https://datahub.io/machine-learning/mushroom#resource-mushroom\",)\n",
        "                       )\n",
        "    #dataset3.show()"
      ],
      "metadata": {
        "id": "_DEkxHsTHfbg"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this project we collected data from different datasets, so it is necessary to create a function to manage this."
      ],
      "metadata": {
        "id": "WU1UOA1EZytF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def collect_data(dataset_dir, data_dir):\n",
        "    for file in glob.iglob('%s/**/*.jpg' % dataset_dir, recursive=True):\n",
        "        copy(file, data_dir)\n",
        "    print(\"Data has been collected form all sub directory\" + dataset_dir + \"to\" + data_dir + \"successfully\")\n"
      ],
      "metadata": {
        "id": "vPZ6YQKbaQNP"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The data was stored on a google drive, therefore it's important to define this"
      ],
      "metadata": {
        "id": "Yfb1YAPOawWR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "    #The original data sourcess path\n",
        "    dataset_dir = r\"../content/drive/MyDrive/dataset/Mashrom_DB/\"\n",
        "\n",
        "    #The path after collecting data\n",
        "    data_dir = r\"../content/drive/MyDrive/dataset/Data/\""
      ],
      "metadata": {
        "id": "7Y1YbHSWbM4B"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Collecting the data"
      ],
      "metadata": {
        "id": "JwtBpT7kdK1f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "    # Collect poisonous data\n",
        "    collect_data(dataset_dir + 'Poisonous', data_dir + 'Train/Poisonous')\n",
        "    # Collect edible data\n",
        "    collect_data(dataset_dir + 'Edible', data_dir + 'Train/Edible')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TURN8QbUdKiI",
        "outputId": "6d257717-97a9-4e7b-dc9c-ebceed745f11"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data has been collected form all sub directory../content/drive/MyDrive/dataset/Mashrom_DB/Poisonousto../content/drive/MyDrive/dataset/Data/Train/Poisonoussuccessfully\n",
            "Data has been collected form all sub directory../content/drive/MyDrive/dataset/Mashrom_DB/Edibleto../content/drive/MyDrive/dataset/Data/Train/Ediblesuccessfully\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train data details"
      ],
      "metadata": {
        "id": "9v10iAHQdV2x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "    #\n",
        "    print(\"*****************\")\n",
        "    train_poisonous_dir = data_dir + 'Train/Poisonous'\n",
        "    num_of_poisonous = train_poisonous_dir\n",
        "    print(\"Number of poisons images is : \" + str(num_of_poisonous))\n",
        "    train_edible_dir = data_dir + 'Train/Edible'\n",
        "    num_of_edible = len (train_edible_dir)\n",
        "    print(\"Number of edible images is : \" + str(num_of_edible))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BOhYlNGhdTyv",
        "outputId": "40758d88-838f-4114-a8e2-5d99b8fd96e1"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*****************\n",
            "Number of poisons images is : ../content/drive/MyDrive/dataset/Data/Train/Poisonous\n",
            "Number of edible images is : 50\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Validation data details"
      ],
      "metadata": {
        "id": "8FVCDFGAd9j4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "    #\n",
        "    print(\"*****************\")\n",
        "    validation_poisonous_dir = data_dir + '/Validate/Poisonous'\n",
        "    num_of_validated_poisonous = len(validation_poisonous_dir)\n",
        "    print(\"Number of validated poisons images is : \" + str(num_of_validated_poisonous))\n",
        "    validation_edible_dir = data_dir + '/Validate', 'Edible'\n",
        "    num_of_validated_edible = len(validation_edible_dir)\n",
        "    print(\"Number of validated edible images is : \" + str(num_of_validated_edible))\n",
        "    #"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HxBW2tTIeAFP",
        "outputId": "44f54b7c-61b1-4efb-b882-64c1896e807d"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*****************\n",
            "Number of validated poisons images is : 57\n",
            "Number of validated edible images is : 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "configuration images size for the Neural Network model\n"
      ],
      "metadata": {
        "id": "0Dw09L7veSid"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "training the images using train_image_generator from keras"
      ],
      "metadata": {
        "id": "ajPI7VbYeoxB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_image_generator = ImageDataGenerator(rescale=1. / 255)  # validation data"
      ],
      "metadata": {
        "id": "pdcfFmJGfcvf"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "validation the images using ImageDataGenerator from keras"
      ],
      "metadata": {
        "id": "15kXONx3fKaF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "validation_image_generator = ImageDataGenerator(rescale=1. / 255)  # validation data"
      ],
      "metadata": {
        "id": "rMuH442GfWbx"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "configuration images size"
      ],
      "metadata": {
        "id": "NIf-rCd-gmHx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "    batch_size = 32\n",
        "    epochs = 10\n",
        "    IMG_HEIGHT = 20\n",
        "    IMG_WIDTH = 20"
      ],
      "metadata": {
        "id": "f3UgDeQEgW2U"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "    train_image_generator = ImageDataGenerator(rescale=1. / 255)  # training data\n",
        "    validation_image_generator = ImageDataGenerator(rescale=1. / 255)  # validation data\n",
        "\n",
        "    train_data_gen = train_image_generator.flow_from_directory(batch_size=batch_size,\n",
        "                                                               directory=data_dir + 'Train',\n",
        "                                                               shuffle=True,\n",
        "                                                               target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "                                                               class_mode='binary')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vHZc0hrKgt0X",
        "outputId": "e985c7ab-e53f-44eb-b2e9-d8ea7933a0f3"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 7 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating a Sequential model where each layer has exactly one input tensor and one output tensor."
      ],
      "metadata": {
        "id": "YxUxt_uPg44W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "    model = Sequential([\n",
        "        Conv2D(16, 3, padding='same', activation='relu', input_shape=(IMG_HEIGHT, IMG_WIDTH, 3)),\n",
        "        MaxPooling2D(),\n",
        "        Conv2D(32, 3, padding='same', activation='relu'),\n",
        "        MaxPooling2D(),\n",
        "        Conv2D(64, 3, padding='same', activation='relu'),\n",
        "        MaxPooling2D(),\n",
        "        Flatten(),\n",
        "        Dense(512, activation='relu'),\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ])"
      ],
      "metadata": {
        "id": "4no_V1U_g8vh"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " print(\"Number of weights after calling the model:\", len(model.weights))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aOZqXaUehC74",
        "outputId": "a32c2755-09f8-474e-9bbb-08bf2c2db8b7"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of weights after calling the model: 10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " Compile the model with Adam optimizer\n",
        ""
      ],
      "metadata": {
        "id": "kcK3YKK4hIGF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "    model.compile(optimizer='adam',\n",
        "                  loss='binary_crossentropy',\n",
        "                  metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "K4BJuHOfhLjV"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Print the summary"
      ],
      "metadata": {
        "id": "9tgIqLPChQRo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xlGDbsF9hTkV",
        "outputId": "03823e7e-b83d-4395-eb83-936583bf5952"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 20, 20, 16)        448       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 10, 10, 16)        0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 10, 10, 32)        4640      \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 5, 5, 32)          0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 5, 5, 64)          18496     \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPoolin  (None, 2, 2, 64)          0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 256)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 512)               131584    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 513       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 155681 (608.13 KB)\n",
            "Trainable params: 155681 (608.13 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    }
  ]
}