{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b25f35c-5f40-41e3-be00-1b84ef42fa84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from efficientnet.tfkeras import EfficientNetB0\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "\n",
    "\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Define paths to the training, validation, and test directories\n",
    "train_dir = r'E:\\Amazon\\ml\\original splitted\\train'\n",
    "test_dir = r'E:\\Amazon\\ml\\original splitted\\test'\n",
    "val_dir = r'E:\\Amazon\\ml\\original splitted\\val'\n",
    "\n",
    "\n",
    "# Define parameters for data generators\n",
    "batch_size = 128\n",
    "target_size = (224, 224)  # Target size for input images\n",
    "\n",
    "# Create ImageDataGenerator instances with data augmentation and normalization for training and validation\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,  # Normalize pixel values to [0,1]\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)  # Only rescale for validation data\n",
    "\n",
    "# Create train_generator and val_generator\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=target_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary',  # Assuming binary classification\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "    val_dir,\n",
    "    target_size=target_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# Create ImageDataGenerator instance for test data\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)  # Only rescale for test data\n",
    "\n",
    "# Create test_generator\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=target_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# Load pre-trained EfficientNetB0 model without top layers\n",
    "base_model = EfficientNetB0(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# Freeze the layers of the pre-trained model except the last few convolutional layers\n",
    "for layer in base_model.layers[:-5]:  # Adjust the number of layers to freeze as per your requirement\n",
    "    layer.trainable = False\n",
    "\n",
    "# Add custom dense layers\n",
    "x = base_model.output\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "x = layers.Dense(256, activation='relu')(x)\n",
    "x = layers.Dropout(0.8)(x)\n",
    "predictions = layers.Dense(1, activation='sigmoid')(x)  # Binary classification, so using sigmoid activation\n",
    "\n",
    "# Combine base model with custom top layers\n",
    "model = models.Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Specify the learning rate\n",
    "learning_rate = 0.001\n",
    "\n",
    "# Compile the model with custom learning rate\n",
    "optimizer = Adam(learning_rate=learning_rate)\n",
    "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "# Define early stopping callback\n",
    "early_stopping = EarlyStopping(monitor='val_accuracy', patience=10)\n",
    "\n",
    "# Train the model with early stopping\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=len(train_generator),\n",
    "    epochs=70,\n",
    "    validation_data=val_generator,\n",
    "    validation_steps=len(val_generator),\n",
    "    callbacks=[early_stopping]\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e722987-e439-4620-b4d7-60c535f53af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "plt.plot(history.history['accuracy'], label='accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='val_accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Plot training history for loss\n",
    "plt.plot(history.history['loss'], label='loss')\n",
    "plt.plot(history.history['val_loss'], label='val_loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6585b844-357a-4cd9-b456-2a5470d1445f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('mushroom_classification_dropout0.8_adam0.001_batch128_5layers_removed.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c413ff-7a9f-4c27-9f67-01711f8c5b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on test set\n",
    "print(\"Predicting on test set...\")\n",
    "test_pred_probs = model.predict(test_generator)\n",
    "test_preds = (test_pred_probs > 0.5).astype(int)\n",
    "\n",
    "\n",
    "# Confusion matrix for test set\n",
    "cm_test = confusion_matrix(test_generator.classes, test_preds)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm_test, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix - Test Set')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5766f01d-0b75-404e-a19b-b5dece04a576",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on validation set\n",
    "print(\"Evaluating the model on validation set...\")\n",
    "val_loss, val_accuracy = model.evaluate(val_generator)\n",
    "print(f\"Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}\")\n",
    "\n",
    "\n",
    "# Generate classification report\n",
    "class_report = classification_report(test_generator.classes, test_preds, target_names=['Class 0', 'Class 1'], output_dict=True)\n",
    "\n",
    "# Convert classification report to DataFrame\n",
    "report_df = pd.DataFrame(class_report).transpose()\n",
    "\n",
    "# Visualize classification report as a table with adjusted font size and 2 decimal places\n",
    "plt.figure(figsize=(10, 6))  # Adjust figure size as needed\n",
    "plt.axis('off')  # Turn off axis\n",
    "table = plt.table(cellText=report_df.round(2).values,  # Round to 2 decimal places\n",
    "                  rowLabels=report_df.index,\n",
    "                  colLabels=report_df.columns,\n",
    "                  cellLoc='center',\n",
    "                  loc='center',\n",
    "                  colWidths=[0.2]*len(report_df.columns),\n",
    "                  bbox=[0, 0, 1, 1])\n",
    "\n",
    "# Adjust font size\n",
    "table.auto_set_font_size(False)\n",
    "table.set_fontsize(10)  # Adjust font size as needed\n",
    "\n",
    "plt.title('Classification Report')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc7bd513-e40b-4267-be48-7e6ed86fb67b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute ROC curve\n",
    "fpr, tpr, thresholds = roc_curve(test_generator.classes, test_pred_probs)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Plot ROC curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, color='blue', lw=2, label='ROC curve (AUC = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='gray', linestyle='--', label='Random')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3745382e-d8fa-41ee-b6af-60b1da97ccab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose an image from the validation set\n",
    "img = val_generator[0][0][0]  # Assuming batch size is 128 and you want to visualize the first image\n",
    "true_label = val_generator[0][1][0]  # Assuming batch size is 128 and you want to get the true label of the first image\n",
    "\n",
    "# Make a prediction on the image\n",
    "prediction = model.predict(np.expand_dims(img, axis=0))\n",
    "predicted_class_index = np.argmax(prediction)\n",
    "predicted_class_label = class_labels[predicted_class_index]  # Assuming class_labels is defined\n",
    "\n",
    "# Define function to compute activation map for a specific layer and filter\n",
    "def compute_activation_map(model, img, layer_name, filter_index):\n",
    "    # Get the specified layer by name\n",
    "    layer = model.get_layer(layer_name)\n",
    "    # Create a submodel that outputs the activation of the specified layer\n",
    "    submodel = tf.keras.models.Model(inputs=model.inputs, outputs=layer.output)\n",
    "    # Compute the activations for the input image\n",
    "    activations = submodel.predict(np.expand_dims(img, axis=0))\n",
    "    # Extract the activations for the specified filter\n",
    "    activations_filter = activations[:, :, :, filter_index]\n",
    "    # Normalize the activations\n",
    "    activations_filter -= activations_filter.mean()\n",
    "    activations_filter /= activations_filter.std() + 1e-5\n",
    "    return activations_filter[0]\n",
    "\n",
    "# Define function to plot activations for a specific layer and filter\n",
    "def plot_activations(activation_map, layer_name, filter_index):\n",
    "    plt.imshow(activation_map, cmap='viridis')\n",
    "    plt.title(f'Layer: {layer_name}, Filter: {filter_index}')\n",
    "    plt.colorbar()\n",
    "    plt.show()\n",
    "    \n",
    "# Define filters to visualize: 3 filters from first layer, 3 from 40th, 3 from last layer\n",
    "filters_to_visualize = [('block1a_activation', i) for i in range(3)] + \\\n",
    "                       [('block6c_activation', i) for i in range(3)] + \\\n",
    "                       [('top_activation', i) for i in range(3)]\n",
    "\n",
    "# Iterate over filters and visualize activations\n",
    "for layer_name, filter_index in filters_to_visualize:\n",
    "    # Compute the activation map for the chosen layer and filter\n",
    "    activation_map = compute_activation_map(model, img, layer_name, filter_index)\n",
    "    # Plot the activation map\n",
    "    plot_activations(activation_map, layer_name, filter_index)\n",
    "\n",
    "# Display the true class label and the predicted class label\n",
    "print(\"True class label:\", true_label)\n",
    "print(\"Predicted class label:\", predicted_class_label)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
